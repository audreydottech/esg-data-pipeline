name: data-pipeline-workflow

on:
  # push: # uncomment to run on push
  schedule:
    - cron: "5 14 * * *" # run every day at 8:05AM central time or 14:05 utc
  workflow_dispatch:  # manual triggers

jobs:
  run-data-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo content
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}  # Use the PAT instead of the default GITHUB_TOKEN
      - name: Setup python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip' # to avoid reinstalling libraries
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run data pipeline
        env:
          FH_API_KEY: ${{ secrets.FH_API_KEY }} # import Finnhub API key
        run: python data_pipeline.py # run data pipeline
      - name: Check for changes # create env variable indicating if any changes were made
        id: git-check
        run: |
          git config user.name 'github-actions'
          git config user.email 'github-actions@github.com'
          git add .
          git diff --staged --quiet || echo "changes=true" >> $GITHUB_ENV
      - name: Commit and push if changes
        if: env.changes == 'true' # if changes made push new data to repo
        run: |
          git commit -m "updated esg stock index"
          git push